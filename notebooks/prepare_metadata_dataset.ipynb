{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5971e281",
   "metadata": {},
   "source": [
    "# AIM : Download VoxCeleb1, extract audio samples and evaluate their quality to build the metadata csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de43e2f",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd437d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch  \n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pesq import pesq\n",
    "from pystoi import stoi\n",
    "import librosa.core\n",
    "import soundfile as sf\n",
    "import torchaudio\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b42ae0",
   "metadata": {},
   "source": [
    "# 1. load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3c627f",
   "metadata": {},
   "source": [
    "We are going to use a subset of LibriSpeech dataset available via torchaudio library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6d9d2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 2000 samples to ../data/librispeech_subset\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:13<00:00, 144.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset prepared in ../data/librispeech_subset\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Use dev-clean (smallest subset) and handle the loading more carefully\n",
    "DATA_DIR = \"../data/librispeech_subset\"\n",
    "RAW_DIR = os.path.join(DATA_DIR, \"raw\")\n",
    "os.makedirs(RAW_DIR, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Download dev-clean (smallest subset, ~337MB)\n",
    "    dataset = torchaudio.datasets.LIBRISPEECH(\n",
    "        root=\"../data\",\n",
    "        url=\"dev-clean\",  # smallest subset\n",
    "        download=True\n",
    "    )\n",
    "    \n",
    "    # Take a small random sample\n",
    "    N_SAMPLES = 2000\n",
    "    total_files = len(dataset)\n",
    "    sampled_indices = random.sample(range(total_files), min(N_SAMPLES, total_files))\n",
    "    \n",
    "    print(f\"Saving {len(sampled_indices)} samples to {RAW_DIR}\")\n",
    "    for idx in tqdm(sampled_indices):\n",
    "        try:\n",
    "            # Load audio\n",
    "            waveform, sample_rate, _, _, _, _ = dataset[idx]\n",
    "            \n",
    "            # Save as WAV\n",
    "            filename = f\"librispeech_sample_{idx:04d}.wav\"\n",
    "            filepath = os.path.join(RAW_DIR, filename)\n",
    "            torchaudio.save(filepath, waveform, sample_rate)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {idx}: {e}\")\n",
    "            continue\n",
    "            \n",
    "    print(f\"Dataset prepared in {RAW_DIR}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Failed to load dataset: {e}\")\n",
    "    print(\"Please check your internet connection and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba643e4",
   "metadata": {},
   "source": [
    "# 2. Prepare audiofiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa433bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 files found.\n"
     ]
    }
   ],
   "source": [
    "AUDIO_DIR = RAW_DIR\n",
    "files = librosa.util.find_files(AUDIO_DIR, ext=[\"wav\"])\n",
    "\n",
    "print(f\"{len(files)} files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5163739",
   "metadata": {},
   "source": [
    "# 3. Calculate audio quality metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28c05380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_to_noise_ratio(clean, noisy):\n",
    "    \"\"\"Calculate Signal-to-Noise Ratio in dB.\"\"\"\n",
    "    noise = noisy - clean\n",
    "    signal_power = torch.mean(clean ** 2)\n",
    "    noise_power = torch.mean(noise ** 2)\n",
    "    snr = 10 * torch.log10(signal_power / (noise_power + 1e-8))\n",
    "    return snr.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2f4b630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [09:43<00:00,  3.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# thresholds - adjust these to be more reasonable\n",
    "MIN_DURATION = 2.0    # seconds\n",
    "PESQ_MIN = 2.5       # To adapt, according to precision of PESQ\n",
    "STOI_MIN = 0.85       # closer to 1.0 meaning better intelligibility\n",
    "SNR_MIN = 10.0       # Need higher SNR for better quality\n",
    "\n",
    "results = []\n",
    "TARGET_SR = 16000\n",
    "\n",
    "for f in tqdm(files):\n",
    "    try:\n",
    "        # Load and resample to required rate for PESQ\n",
    "        y, sr = librosa.load(f, sr=TARGET_SR, mono=True)\n",
    "        if len(y) < sr * MIN_DURATION:\n",
    "            continue\n",
    "\n",
    "        # Convert to torch tensor and normalize\n",
    "        y = torch.from_numpy(y).float()\n",
    "        y = y / (torch.abs(y).max() + 1e-8)\n",
    "\n",
    "        # Instead of adding noise, use the original audio\n",
    "        # Calculate background noise level from silent segments\n",
    "        frame_length = 2048\n",
    "        hop_length = 512\n",
    "        rms = librosa.feature.rms(y=y.numpy(), frame_length=frame_length, hop_length=hop_length)\n",
    "        noise_floor = np.percentile(rms, 10)  # estimate noise floor from quietest segments\n",
    "        \n",
    "        # Calculate SNR using estimated noise floor\n",
    "        signal_power = torch.mean(y ** 2)\n",
    "        snr_score = 10 * torch.log10(signal_power / (noise_floor + 1e-8))\n",
    "\n",
    "        # Calculate PESQ and STOI using clean audio as reference\n",
    "        # This assumes the original audio is clean enough\n",
    "        pesq_score = pesq(TARGET_SR, y.numpy(), y.numpy(), \"wb\")\n",
    "        stoi_score = stoi(y.numpy(), y.numpy(), TARGET_SR, extended=False)\n",
    "\n",
    "        results.append({\n",
    "            \"file\": f,\n",
    "            \"duration_s\": len(y) / TARGET_SR,\n",
    "            \"pesq\": pesq_score,\n",
    "            \"stoi\": stoi_score,\n",
    "            \"snr\": snr_score.item()\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {f}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Filter to keep only higher quality samples\n",
    "df_filtered = df[\n",
    "    (df[\"pesq\"] >= PESQ_MIN) &\n",
    "    (df[\"stoi\"] >= STOI_MIN) &\n",
    "    (df[\"snr\"] >= SNR_MIN)\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05167b45",
   "metadata": {},
   "source": [
    "# 4. Filter and save metadata CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af8f7d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low quality samples: 495 samples kept.\n",
      "New metadata saved: ../data/librispeech_subset\\metadata.csv\n",
      "Successfully processed 495 files\n",
      "Files saved to: c:\\Users\\leami\\Documents\\projet_git\\GaussBuster\\data\\librispeech_subset\\high_quality_audio\n",
      "Metadata saved to: ../data/librispeech_subset\\metadata.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"Low quality samples: {len(df_filtered)} samples kept.\")\n",
    "\n",
    "# Copy selected files to a new directory\n",
    "AUDIO_DIR_HIGH_QUALITY = \"../data/librispeech_subset/high_quality_audio\"\n",
    "metadata_path = os.path.join(DATA_DIR, \"metadata.csv\")\n",
    "\n",
    "# Convert all paths to absolute paths\n",
    "AUDIO_DIR_HIGH_QUALITY = os.path.abspath(AUDIO_DIR_HIGH_QUALITY)\n",
    "DATA_DIR = os.path.abspath(DATA_DIR)\n",
    "\n",
    "metadata_data = {\n",
    "    \"file\": [],\n",
    "    \"duration_s\": [],\n",
    "    \"pesq\": [],\n",
    "    \"stoi\": [],\n",
    "    \"snr\": []\n",
    "}\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(AUDIO_DIR_HIGH_QUALITY, exist_ok=True)\n",
    "\n",
    "for _, row in df_filtered.iterrows():\n",
    "    try:\n",
    "        # Convert source path to absolute path\n",
    "        src_path = os.path.abspath(row[\"file\"])\n",
    "        \n",
    "        if os.path.exists(src_path):\n",
    "            filename = os.path.basename(src_path)\n",
    "            dest_path = os.path.join(AUDIO_DIR_HIGH_QUALITY, filename)\n",
    "            \n",
    "            # Copy file\n",
    "            shutil.copy2(src_path, dest_path)\n",
    "            \n",
    "            # Store only the filename in metadata\n",
    "            metadata_data[\"file\"].append(filename)\n",
    "            metadata_data[\"duration_s\"].append(row[\"duration_s\"])\n",
    "            metadata_data[\"pesq\"].append(row[\"pesq\"])\n",
    "            metadata_data[\"stoi\"].append(row[\"stoi\"])\n",
    "            metadata_data[\"snr\"].append(row[\"snr\"])\n",
    "        else:\n",
    "            print(f\"Source file not found: {src_path}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {src_path}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Save the new metadata CSV\n",
    "df_new_metadata = pd.DataFrame(metadata_data)\n",
    "df_new_metadata.to_csv(metadata_path, index=False)\n",
    "print(f\"New metadata saved: {metadata_path}\")\n",
    "\n",
    "# Print summary\n",
    "print(f\"Successfully processed {len(metadata_data['file'])} files\")\n",
    "print(f\"Files saved to: {AUDIO_DIR_HIGH_QUALITY}\")\n",
    "print(f\"Metadata saved to: {metadata_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
